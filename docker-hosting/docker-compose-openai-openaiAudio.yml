services:
  aitalkmaster:
    build:
      context: ../
      dockerfile: docker-hosting/aitalkmaster.Dockerfile
    container_name: aitalkmaster
    # Remove external port exposure - only accessible via nginx proxy
    expose:
      - "6000"
    networks:
      - streaming-network
    extra_hosts:
      - "host.docker.internal:host-gateway"
    volumes:
      - generated_audio_openai:/app/generated-audio
      - aitalkmaster_logs_openai:/app/logs
      - ../openai_key.txt:/app/openai_key.txt:ro
      - ../aitalkmaster-server/configs/docker-openai-openai.yml:/app/config.yml:ro
    environment:
      - PYTHONUNBUFFERED=1
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:6000/statusAitalkmaster"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  liquidsoap:
    build:
      context: ./
      dockerfile: liquidsoap.Dockerfile
    restart: unless-stopped
    volumes:
      - liquidsoap_logs_openai:/var/log/liquidsoap
      - generated_audio_openai:/generated-audio:ro
    environment:
      - LIQUIDSOAP_LOG_LEVEL=3
    depends_on:
      - icecast
    networks:
      - streaming-network

    # icecast configs lie in /etc/icecast2/icecast.xml
  icecast:
    #image: moul/icecast:latest
    build:
      context: ../
      dockerfile: docker-hosting/icecast.Dockerfile
    restart: unless-stopped
    expose:
      - "8000"
    environment:
      - ICECAST_SOURCE_PASSWORD=srcpassword
      - ICECAST_RELAY_PASSWORD=password
      - ICECAST_ADMIN_PASSWORD=password
      - ICECAST_PASSWORD=password
      - ICECAST_HOSTNAME=localhost
    volumes:
      - icecast_logs_openai:/var/log/icecast2
    networks:
      - streaming-network

  # Nginx proxy to hide backend containers and provide unified API endpoints
  nginx:
    image: nginx:alpine
    container_name: aitalkmaster-nginx
    restart: unless-stopped
    ports:
      - "7000:80"  # External port
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf:ro
      - nginx_logs_openai:/var/log/nginx
      - generated_audio_openai:/generated-audio:ro # nginx needs this to check if the stream is active
    depends_on:
      - aitalkmaster
      - icecast
    networks:
      - streaming-network
    healthcheck:
      test: ["CMD", "wget", "--quiet", "--tries=1", "--spider", "http://localhost/nginx-health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  streaming-network:
    driver: bridge

volumes:
  generated_audio_openai:
    name: hosting_generated_audio_openai
  aitalkmaster_logs_openai:
    name: hosting_aitalkmaster_logs_openai
  liquidsoap_logs_openai:
    name: hosting_liquidsoap_logs_openai
  icecast_logs_openai:
    name: hosting_icecast_logs_openai
  nginx_logs_openai:
    name: hosting_nginx_logs_openai